{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN. Part 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn8ilyMiMMEX",
        "colab_type": "text"
      },
      "source": [
        "# Сверточные нейронные сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y0cfIJqNQHx",
        "colab_type": "text"
      },
      "source": [
        "## Что такое сверточный слой?\n",
        "\n",
        "Сверточный слой - более упрощенный слой, который позволяет сократить количество параметров сети. Важной особенностью слоя является то, что производится операция свертки слоя c набором весов. \n",
        "\n",
        "Формально, математическая модель определена следующим образом:\n",
        "\n",
        "рассмотрим двумерный канал изображения размером $W \\times H$, определим сверточный слой с ядром размера $K \\times K$ как операцию свертки для каждого квадрата размером $K \\times K$ с матрицей весов.\n",
        "\n",
        "Параметры сверточного слоя:\n",
        "\n",
        "* количество входных фильтров - $in$\n",
        "* количество выходных фильтров - $out$.\n",
        "\n",
        "Для каждого фильтра для пикселя выход определяется следующим образом:\n",
        "\n",
        "$$\n",
        "   out_{i,j} = \\sum_{s = -[(k-1)/2]}^{[k/2]} \\sum_{t=-[(k-1)/2]}^{[k/2]} W_{s, t} I_{i +s, j + t} + b,\n",
        "$$\n",
        "\n",
        "где $W$ - матрица весов для фильтра, $b$ - смещение (bias), $I$ - фильтр (двумерный массив размера $W \\times H$), к которому применяется свертка.\n",
        "\n",
        "**Вопрос**. Какое количество тренируемых параметров используется в сверточном слое?\n",
        "\n",
        "**Ответ** $(K \\times K + 1) \\times in \\times out$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu_lZbDquH83",
        "colab_type": "text"
      },
      "source": [
        "## Дополнительные параметры сверточного слоя\n",
        "\n",
        "Дополнительно необходимо определить следующие параметры сверточного слоя:\n",
        "* stride - шаг, с каким производится свертка\n",
        "* padding - начальное и конечное положение, с которого начинается свертка.\n",
        "\n",
        "**Вопрос.** Какой будет размер выходного фильтра, если используется свертка с ядром $K \\times K$, stride - (1, 1), начало и конец находятся в вершинах изображения?\n",
        "\n",
        "**Ответ.** $ (W - K + 1) \\times (H - K + 1)$.\n",
        "\n",
        "Чтобы размер фильтра не менялся, применяется следующая стратегия: входной фильтр дополняется нулями таким образом, чтобы размер выходного слоя был $W \\times H$. Такая стратегия называется same padding. Изначальная стратегия называется valid padding.\n",
        "\n",
        "Приступим к реализации сверточного слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuM2w5OdNTdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def conv2d_one_filter(X, W, padding='same', stride=(1, 1)):\n",
        "    \"\"\"\n",
        "        @param X: input image, [w \\times h]\n",
        "        @param W: weights, [K \\times K]\n",
        "        @param padding: padding type - same or full\n",
        "    \"\"\"\n",
        "    \n",
        "    kernel_y, kernel_x = W.shape[:2]\n",
        "    \n",
        "    # Calculating shape of new pad\n",
        "    \n",
        "    if padding == 'same':\n",
        "        y_shape = X.shape[0] + kernel_y - 1\n",
        "        x_shape = X.shape[1] + kernel_x - 1\n",
        "    else:\n",
        "        y_shape, x_shape = X.shape[:2]\n",
        "    \n",
        "    x_padded = np.zeros((y_shape, x_shape), dtype=X.dtype)\n",
        "    print(x_padded.shape)\n",
        "    \n",
        "    if padding == 'valid':\n",
        "        padding_left = 0\n",
        "        padding_top = 0\n",
        "    else:\n",
        "        padding_left = (kernel_x - 1) // 2\n",
        "        padding_top = (kernel_y - 1) // 2\n",
        "    \n",
        "    x_padded[\n",
        "        padding_top:padding_top + X.shape[0],\n",
        "        padding_left:padding_left + X.shape[1]\n",
        "    ] = X\n",
        "\n",
        "    result = np.zeros((x_padded.shape[0] - kernel_y + 1, x_padded.shape[1] - kernel_x + 1))\n",
        "    \n",
        "    for y in range(x_padded.shape[0]):\n",
        "        for x in range(x_padded.shape[1]):\n",
        "            if y + kernel_y > x_padded.shape[0] or x + kernel_x > x_padded.shape[1]:\n",
        "                continue\n",
        "            result[y, x] = np.sum(x_padded[y:y + kernel_y, x:x + kernel_x] * W)\n",
        "    return result\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHe6XxUXw1KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.signal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE64oiFUw2T8",
        "colab_type": "code",
        "outputId": "b7fbf417-e7ee-4a8d-fbc6-265333093a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "conv2d_one_filter(np.array([\n",
        "   [1, 2, 3],\n",
        "   [4, 5, 6],\n",
        "   [7, 8, 9]\n",
        "]), np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 94., 154., 106.],\n",
              "       [186., 285., 186.],\n",
              "       [106., 154.,  94.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkYNiro7yOJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaY1ruOIz8p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "a = tf.placeholder(tf.float32, [1, 3, 3, 1])\n",
        "w = tf.placeholder(tf.float32, [3, 3, 1, 1])\n",
        "out_same = tf.nn.conv2d(a, w, padding='SAME')\n",
        "out_valid = tf.nn.conv2d(a, w, padding='VALID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99vctnk70ZoY",
        "colab_type": "code",
        "outputId": "5b788917-fb54-47c4-d62d-e1db274320bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sess.run(out_same, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "    w: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((3, 3, 1, 1))\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 94.],\n",
              "         [154.],\n",
              "         [106.]],\n",
              "\n",
              "        [[186.],\n",
              "         [285.],\n",
              "         [186.]],\n",
              "\n",
              "        [[106.],\n",
              "         [154.],\n",
              "         [ 94.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VKhVVmE0oqA",
        "colab_type": "code",
        "outputId": "db33465e-4ddf-4832-dbb7-0e8d4cbc3092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sess.run(out_valid, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "    w: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((3, 3, 1, 1))\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[285.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ3A6rr60iDS",
        "colab_type": "text"
      },
      "source": [
        "##  Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsN5QWZl0f1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZYNNqjr1QQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.placeholder(tf.float32, (1, 3, 3, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54mtRlzc1Vop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pool_valid = tf.nn.max_pool2d(a, ksize=(2, 2), strides=(1, 1), padding='VALID')\n",
        "pool_same = tf.nn.max_pool2d(a, ksize=(2, 2), strides=(1, 1), padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xqnRR-c1Y_Z",
        "colab_type": "code",
        "outputId": "5d27fac4-762d-42d1-d284-c4647e8890b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sess.run(pool_valid, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[5.],\n",
              "         [6.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNcPUMsd1aAI",
        "colab_type": "code",
        "outputId": "695a847e-cde3-4d18-b144-7955928189d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sess.run(pool_same, feed_dict={\n",
        "    a: np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]).reshape((1, 3, 3, 1)),\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[5.],\n",
              "         [6.],\n",
              "         [6.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.],\n",
              "         [9.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.],\n",
              "         [9.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rtWJyJT2tgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBJya11N13PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pooling(X, kernel_size=(2, 2), padding='same', strides=(2, 2)):\n",
        "    height, width = X.shape[:2]\n",
        "    if padding == 'same':\n",
        "        out_height = math.ceil(height / strides[0])\n",
        "        out_width = math.ceil(width / strides[1])\n",
        "    else:\n",
        "        out_height = (height - kernel_size[0] + 1) // strides[0]\n",
        "        out_width = (width - kernel_size[1] + 1) // strides[1]\n",
        "    \n",
        "    result = np.zeros((out_height, out_width), dtype=X.dtype)\n",
        "    \n",
        "    for y in range(out_height):\n",
        "        for x in range(out_width):\n",
        "            start_y = y * strides[0]\n",
        "            start_x = x * strides[1]\n",
        "            \n",
        "            result[y, x] = np.max(\n",
        "                X[\n",
        "                    start_y:start_y + kernel_size[0],\n",
        "                    start_x:start_x + kernel_size[1]\n",
        "                ]\n",
        "            )\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQbwem4h4NkA",
        "colab_type": "code",
        "outputId": "0fcabb59-d798-4793-8fdb-f4d031b75a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 6],\n",
              "       [8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoNpdzQ44T3v",
        "colab_type": "code",
        "outputId": "efec79f0-484d-4f20-c12b-c86959bb93c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]),\n",
        "    padding='valid'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6N1Kwbk4WpP",
        "colab_type": "code",
        "outputId": "305841d8-0700-48be-ddc0-8561c824ec5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]),\n",
        "    padding='valid',\n",
        "    strides=(1, 1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 6],\n",
              "       [8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cet0I6d4ZVX",
        "colab_type": "code",
        "outputId": "f87941d9-eac3-4771-a52c-84151f6700e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "max_pooling(\n",
        "    X=np.array([\n",
        "        [1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]\n",
        "    ]),\n",
        "    padding='same',\n",
        "    strides=(1, 1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 6, 6],\n",
              "       [8, 9, 9],\n",
              "       [8, 9, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYt-zwnDK5jg",
        "colab_type": "text"
      },
      "source": [
        "## Базовые блоки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqQE9YAx5eJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "def conv_layer(\n",
        "        input_tensor,\n",
        "        output_channels,\n",
        "        name='conv',\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='SAME'\n",
        "    ):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        input_shape = input_tensor.get_shape().as_list()\n",
        "        \n",
        "        input_channels = input_shape[-1]\n",
        "        \n",
        "        print(input_channels, output_channels)\n",
        "        \n",
        "        weights = tf.get_variable(name='weights', shape=[\n",
        "            kernel_size[0], kernel_size[1], input_channels, output_channels\n",
        "        ])\n",
        "        \n",
        "        bias = tf.get_variable(\n",
        "            name='bias',\n",
        "            shape=[output_channels],\n",
        "            initializer=tf.zeros_initializer()\n",
        "        )\n",
        "        \n",
        "        conv = tf.nn.conv2d(\n",
        "            input=input_tensor,\n",
        "            filter=weights,\n",
        "            strides=strides,\n",
        "            padding='SAME',\n",
        "            name='conv'\n",
        "        )\n",
        "        \n",
        "        output = tf.nn.bias_add(conv, bias, name='output')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zucgYvJtK_o8",
        "colab_type": "code",
        "outputId": "f3f66083-9fec-4379-a78d-ef861998f22e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "a = tf.placeholder(tf.float32, (1, 3, 3, 1))\n",
        "b = conv_layer(a, 3)\n",
        "example = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]).reshape((1, 3, 3, 1))\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b, feed_dict={\n",
        "    a: example\n",
        "})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 05:55:08.455413 140287620593536 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-0.03561094, -2.5681984 , -0.18274444],\n",
              "         [ 1.199398  , -2.0457542 ,  0.7028016 ],\n",
              "         [ 0.37761962, -0.17797205,  3.029345  ]],\n",
              "\n",
              "        [[-0.6255276 , -3.8368087 , -0.383636  ],\n",
              "         [ 1.5125254 , -1.5389371 ,  0.21473914],\n",
              "         [ 0.53970647,  0.22062658,  3.9709496 ]],\n",
              "\n",
              "        [[-0.5383489 ,  1.4607241 , -0.7147733 ],\n",
              "         [ 0.690181  ,  3.8535058 , -1.4720438 ],\n",
              "         [-1.4785525 ,  0.9838684 , -1.1894754 ]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZFAY4gMLF0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pool(\n",
        "    input_tensor,\n",
        "    kernel_size=(2, 2),\n",
        "    strides=(2, 2),\n",
        "    padding='SAME',\n",
        "    name='pool'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        output = tf.nn.max_pool2d(input_tensor, ksize=kernel_size, strides=strides, padding=padding, name='pool')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOyKj4h7MCEN",
        "colab_type": "code",
        "outputId": "a258d9b6-e76b-4655-89ee-8cd949008618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "a = tf.placeholder(tf.float32, (1, 3, 3, 1))\n",
        "b = max_pool(a)\n",
        "example = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]).reshape((1, 3, 3, 1))\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b, feed_dict={\n",
        "    a: example\n",
        "})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[5.],\n",
              "         [6.]],\n",
              "\n",
              "        [[8.],\n",
              "         [9.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb0b_cQZ1STL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(\n",
        "    input_tensor,\n",
        "    name='flatten'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        shape = input_tensor.get_shape().as_list()[1:]\n",
        "        num_elements = np.prod(shape)\n",
        "        return tf.reshape(input_tensor, [-1, num_elements], name='reshape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw9fQKqU1-2G",
        "colab_type": "code",
        "outputId": "382c1f55-0555-4cd2-8df2-729c766f1870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.zeros([1, 3, 3, 1])\n",
        "b = flatten(a)\n",
        "sess.run(b)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCu9X5fj2Hxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense(\n",
        "    input_tensor,\n",
        "    output_neurons,\n",
        "    name='fc'\n",
        "):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        input_neurons = input_tensor.get_shape().as_list()[1]\n",
        "        \n",
        "        weights = tf.get_variable(\n",
        "            name='weights',\n",
        "            shape=[input_neurons, output_neurons]\n",
        "        )\n",
        "        \n",
        "        bias = tf.get_variable(\n",
        "            name='bias',\n",
        "            shape=[output_neurons]\n",
        "        )\n",
        "        \n",
        "        product = tf.matmul(input_tensor, weights, name='product')\n",
        "        \n",
        "        output = tf.nn.bias_add(product, bias, name='output')\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZh2Ho_G3EMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.zeros([1, 9])\n",
        "b = dense(a, 18, name='fc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYGBvW6_3JkZ",
        "colab_type": "code",
        "outputId": "aaedfa8f-c395-49ef-fa1c-e26b37da1e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.3247372 ,  0.266706  , -0.03641906,  0.34226698,  0.15396553,\n",
              "        -0.2293282 ,  0.18490332, -0.01789281, -0.29601657, -0.02632582,\n",
              "         0.35386634, -0.3678915 ,  0.02026698,  0.25488275, -0.29531676,\n",
              "        -0.313573  ,  0.3309955 ,  0.3230583 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f59keuqT4bvm",
        "colab_type": "text"
      },
      "source": [
        "##Архитектуры сетей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1XGQeK5Hrd",
        "colab_type": "text"
      },
      "source": [
        "### LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzxeau5d3SSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(x, output_channels, name, kernel_size=(3, 3), padding='SAME'):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        conv_out = conv_layer(x, output_channels, kernel_size=kernel_size, padding=padding)\n",
        "        activation = tf.nn.relu(conv_out, name='relu')\n",
        "    return activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiJ-D0Ww3-By",
        "colab_type": "code",
        "outputId": "5ee7c082-b3d0-401c-b0b4-0facd6f44c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.zeros((1, 3, 3, 1))\n",
        "b = conv_block(a, 6, 'conv1')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IjnuWs4fHK",
        "colab_type": "code",
        "outputId": "c122ae8f-8211-4e13-b4c3-b769f6c83fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(b).shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3, 3, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy3B_3FT4wM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def le_net(input_tensor):\n",
        "    with tf.variable_scope('le_net', reuse=tf.AUTO_REUSE):\n",
        "        conv1_out = conv_block(\n",
        "            input_tensor, 6,\n",
        "            name='conv1',\n",
        "            kernel_size=(5, 5),\n",
        "            padding='VALID'\n",
        "        )\n",
        "        pool1_out = max_pool(conv1_out, name='pool1')\n",
        "        conv2_out = conv_block(\n",
        "            pool1_out, 16,\n",
        "            name='conv2',\n",
        "            kernel_size=(5, 5),\n",
        "            padding='VALID'\n",
        "        )\n",
        "        \n",
        "        pool2_out = max_pool(conv2_out, name='pool2')\n",
        "        \n",
        "        flatten_out = flatten(pool2_out)\n",
        "        \n",
        "        fc1_out = dense(flatten_out, 120, name='fc1')\n",
        "        fc2_out = dense(fc1_out, 84, name='fc2')\n",
        "        \n",
        "        output = dense(fc2_out, 10, name='fc3')\n",
        "    return output\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY0ah_3_6v26",
        "colab_type": "code",
        "outputId": "52c64606-8dd8-4f19-e565-7df0daac2da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "digits_placeholder = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
        "logits = le_net(digits_placeholder)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 6\n",
            "6 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqOCKdLqxY5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_placeholder = tf.placeholder(tf.float32, [None, 10], name='le_net_labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CNXR58_xkcN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "92d2b2f0-492b-487b-8333-1ba1a10c45d3"
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    labels=labels_placeholder,\n",
        "    logits=logits\n",
        ")\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 05:55:12.950386 140287620593536 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fipubrdsxwGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='le_net')\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss, var_list=le_net_trainable_variables)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QpPR2KaWeyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_net_predictions = tf.argmax(logits, axis=1)\n",
        "le_net_target = tf.argmax(labels_placeholder, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTe05E06Xvxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('le_net/metrics/train/'):\n",
        "    le_net_accuracy_train, le_net_accuracy_train_op = tf.metrics.accuracy(\n",
        "        labels=le_net_target,\n",
        "        predictions=le_net_predictions\n",
        "    )\n",
        "    le_net_train_loss, le_net_train_loss_op = tf.metrics.mean(values=loss, name='loss')\n",
        "with tf.name_scope('le_net/metrics/val/'):\n",
        "    le_net_accuracy_val, le_net_accuracy_val_op = tf.metrics.accuracy(\n",
        "        labels=le_net_target,\n",
        "        predictions=le_net_predictions\n",
        "    )\n",
        "    le_net_val_loss, le_net_val_loss_op = tf.metrics.mean(values=loss, name='loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9_-qRSrkOBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "da659a8d-a223-4c27-c0b3-0755f340cb09"
      },
      "source": [
        "tf.local_variables()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'le_net/metrics/train/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/accuracy_1/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/accuracy_1/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss_1/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss_1/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy_1/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy_1/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss_1/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss_1/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/accuracy_2/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/accuracy_2/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss_2/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/train/loss_2/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy_2/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/accuracy_2/count:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss_2/total:0' shape=() dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/metrics/val/loss_2/count:0' shape=() dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD1gGzyOWEPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "y_train_labels = to_categorical(y_train)\n",
        "y_test_labels = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPykTuBNYrHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reset_metrics(scope):\n",
        "#     print(tf.local_variables())\n",
        "    stream_variables = [v for v in tf.local_variables() if scope in v.name]\n",
        "    sess.run(tf.variables_initializer(stream_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYD8nu_KzeLZ",
        "colab_type": "code",
        "outputId": "b172b277-7911-4216-8b48-459090944705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check that data is ready\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n",
        "sess.run([loss, le_net_accuracy_train], feed_dict={\n",
        "    digits_placeholder: X_train[:10],\n",
        "    labels_placeholder: y_train_labels[:10]\n",
        "})"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37.533615, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEN0LwAYyIAC",
        "colab_type": "code",
        "outputId": "2fe3beb1-32cd-440d-922e-970204b61fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "le_net_trainable_variables"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'le_net/conv1/conv/weights:0' shape=(5, 5, 3, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/conv1/conv/bias:0' shape=(6,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/conv2/conv/weights:0' shape=(5, 5, 6, 16) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/conv2/conv/bias:0' shape=(16,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc1/weights:0' shape=(1024, 120) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc1/bias:0' shape=(120,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc2/weights:0' shape=(120, 84) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc2/bias:0' shape=(84,) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc3/weights:0' shape=(84, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'le_net/fc3/bias:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ4jtls_UNpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterate_batches(X, y, batch_size, shuffle=True):\n",
        "    assert len(X) == len(y)\n",
        "    \n",
        "    indices = np.arange(len(X))\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    \n",
        "    for index in range(0, len(X), batch_size):\n",
        "        yield X[index:index + batch_size], y[index:index + batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9L01pAmzEUn",
        "colab_type": "code",
        "outputId": "d054f6aa-7151-4a01-cbea-e425ff7c699b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch_num in range(50):\n",
        "    reset_metrics('le_net/metrics/train')\n",
        "    reset_metrics('le_net/metrics/val')\n",
        "    for X_batch, y_batch in iterate_batches(X_train, y_train_labels, 500):\n",
        "        _, _, _ = sess.run([optimizer, le_net_accuracy_train_op, le_net_train_loss_op], feed_dict={\n",
        "            digits_placeholder: X_batch,\n",
        "            labels_placeholder: y_batch\n",
        "        })\n",
        "        # print(loss_value, accuracy)\n",
        "    \n",
        "    print(f'Epoch {epoch_num + 1} train [acc, loss]:', sess.run([le_net_accuracy_train, le_net_train_loss]))\n",
        "    \n",
        "    for X_batch, y_batch in iterate_batches(X_test, y_test_labels, 500, shuffle=False):\n",
        "        _, _ = sess.run([le_net_accuracy_val_op, le_net_val_loss_op], feed_dict = {\n",
        "            digits_placeholder: X_batch,\n",
        "            labels_placeholder: y_batch\n",
        "        })\n",
        "    print(f'Epoch {epoch_num + 1} val [acc, loss]:', sess.run([le_net_accuracy_val, le_net_val_loss]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train [acc, loss]: [0.12302, 3.3215249]\n",
            "Epoch 1 val [acc, loss]: [0.1512, 0.36490077]\n",
            "Epoch 2 train [acc, loss]: [0.16608, 0.35136887]\n",
            "Epoch 2 val [acc, loss]: [0.187, 0.33783063]\n",
            "Epoch 3 train [acc, loss]: [0.1994, 0.3302531]\n",
            "Epoch 3 val [acc, loss]: [0.219, 0.32274953]\n",
            "Epoch 4 train [acc, loss]: [0.23234, 0.3169203]\n",
            "Epoch 4 val [acc, loss]: [0.2463, 0.31234303]\n",
            "Epoch 5 train [acc, loss]: [0.26328, 0.30720618]\n",
            "Epoch 5 val [acc, loss]: [0.2731, 0.3045999]\n",
            "Epoch 6 train [acc, loss]: [0.28178, 0.2989803]\n",
            "Epoch 6 val [acc, loss]: [0.2922, 0.2977122]\n",
            "Epoch 7 train [acc, loss]: [0.30046, 0.29220814]\n",
            "Epoch 7 val [acc, loss]: [0.3115, 0.29127377]\n",
            "Epoch 8 train [acc, loss]: [0.31316, 0.28656602]\n",
            "Epoch 8 val [acc, loss]: [0.3266, 0.2857734]\n",
            "Epoch 9 train [acc, loss]: [0.32808, 0.28179651]\n",
            "Epoch 9 val [acc, loss]: [0.3318, 0.2822675]\n",
            "Epoch 10 train [acc, loss]: [0.3384, 0.27842686]\n",
            "Epoch 10 val [acc, loss]: [0.3347, 0.27977246]\n",
            "Epoch 11 train [acc, loss]: [0.34684, 0.27575427]\n",
            "Epoch 11 val [acc, loss]: [0.3401, 0.2775193]\n",
            "Epoch 12 train [acc, loss]: [0.35142, 0.27347565]\n",
            "Epoch 12 val [acc, loss]: [0.3481, 0.27556273]\n",
            "Epoch 13 train [acc, loss]: [0.35704, 0.27141076]\n",
            "Epoch 13 val [acc, loss]: [0.3547, 0.2734968]\n",
            "Epoch 14 train [acc, loss]: [0.36222, 0.26962617]\n",
            "Epoch 14 val [acc, loss]: [0.3597, 0.27171358]\n",
            "Epoch 15 train [acc, loss]: [0.36482, 0.26812315]\n",
            "Epoch 15 val [acc, loss]: [0.3638, 0.27045676]\n",
            "Epoch 16 train [acc, loss]: [0.37006, 0.26668477]\n",
            "Epoch 16 val [acc, loss]: [0.37, 0.26929253]\n",
            "Epoch 17 train [acc, loss]: [0.37456, 0.26534078]\n",
            "Epoch 17 val [acc, loss]: [0.3752, 0.2682178]\n",
            "Epoch 18 train [acc, loss]: [0.37846, 0.26417878]\n",
            "Epoch 18 val [acc, loss]: [0.3781, 0.26740533]\n",
            "Epoch 19 train [acc, loss]: [0.38064, 0.26307502]\n",
            "Epoch 19 val [acc, loss]: [0.3832, 0.26652008]\n",
            "Epoch 20 train [acc, loss]: [0.38448, 0.2621113]\n",
            "Epoch 20 val [acc, loss]: [0.3849, 0.26553312]\n",
            "Epoch 21 train [acc, loss]: [0.3878, 0.2610524]\n",
            "Epoch 21 val [acc, loss]: [0.3868, 0.26497772]\n",
            "Epoch 22 train [acc, loss]: [0.39082, 0.26017988]\n",
            "Epoch 22 val [acc, loss]: [0.3887, 0.2643652]\n",
            "Epoch 23 train [acc, loss]: [0.39432, 0.25938556]\n",
            "Epoch 23 val [acc, loss]: [0.3908, 0.2639634]\n",
            "Epoch 24 train [acc, loss]: [0.39578, 0.25865865]\n",
            "Epoch 24 val [acc, loss]: [0.3922, 0.26354998]\n",
            "Epoch 25 train [acc, loss]: [0.39858, 0.2578959]\n",
            "Epoch 25 val [acc, loss]: [0.3946, 0.2624455]\n",
            "Epoch 26 train [acc, loss]: [0.40136, 0.2570755]\n",
            "Epoch 26 val [acc, loss]: [0.3979, 0.26236364]\n",
            "Epoch 27 train [acc, loss]: [0.40354, 0.25633913]\n",
            "Epoch 27 val [acc, loss]: [0.3972, 0.26254904]\n",
            "Epoch 28 train [acc, loss]: [0.40622, 0.25571916]\n",
            "Epoch 28 val [acc, loss]: [0.3986, 0.26237053]\n",
            "Epoch 29 train [acc, loss]: [0.40766, 0.25503945]\n",
            "Epoch 29 val [acc, loss]: [0.3968, 0.2620905]\n",
            "Epoch 30 train [acc, loss]: [0.41126, 0.25441462]\n",
            "Epoch 30 val [acc, loss]: [0.3949, 0.26234683]\n",
            "Epoch 31 train [acc, loss]: [0.41326, 0.25382897]\n",
            "Epoch 31 val [acc, loss]: [0.3989, 0.26179284]\n",
            "Epoch 32 train [acc, loss]: [0.4144, 0.25324193]\n",
            "Epoch 32 val [acc, loss]: [0.4023, 0.26026747]\n",
            "Epoch 33 train [acc, loss]: [0.41628, 0.25267944]\n",
            "Epoch 33 val [acc, loss]: [0.4048, 0.25999838]\n",
            "Epoch 34 train [acc, loss]: [0.4195, 0.25203145]\n",
            "Epoch 34 val [acc, loss]: [0.4122, 0.25783136]\n",
            "Epoch 35 train [acc, loss]: [0.42192, 0.2513945]\n",
            "Epoch 35 val [acc, loss]: [0.4127, 0.25665736]\n",
            "Epoch 36 train [acc, loss]: [0.42384, 0.25076917]\n",
            "Epoch 36 val [acc, loss]: [0.4149, 0.255727]\n",
            "Epoch 37 train [acc, loss]: [0.4269, 0.2501177]\n",
            "Epoch 37 val [acc, loss]: [0.4184, 0.25506133]\n",
            "Epoch 38 train [acc, loss]: [0.42878, 0.2494816]\n",
            "Epoch 38 val [acc, loss]: [0.4214, 0.25418553]\n",
            "Epoch 39 train [acc, loss]: [0.43104, 0.24893998]\n",
            "Epoch 39 val [acc, loss]: [0.4244, 0.25361145]\n",
            "Epoch 40 train [acc, loss]: [0.43334, 0.24833742]\n",
            "Epoch 40 val [acc, loss]: [0.4256, 0.2531259]\n",
            "Epoch 41 train [acc, loss]: [0.4362, 0.24767204]\n",
            "Epoch 41 val [acc, loss]: [0.4303, 0.25217682]\n",
            "Epoch 42 train [acc, loss]: [0.43964, 0.24673617]\n",
            "Epoch 42 val [acc, loss]: [0.4313, 0.25147822]\n",
            "Epoch 43 train [acc, loss]: [0.4428, 0.24597783]\n",
            "Epoch 43 val [acc, loss]: [0.431, 0.2510617]\n",
            "Epoch 44 train [acc, loss]: [0.44656, 0.24520627]\n",
            "Epoch 44 val [acc, loss]: [0.4344, 0.25000566]\n",
            "Epoch 45 train [acc, loss]: [0.44894, 0.2444194]\n",
            "Epoch 45 val [acc, loss]: [0.4381, 0.24952285]\n",
            "Epoch 46 train [acc, loss]: [0.451, 0.24345315]\n",
            "Epoch 46 val [acc, loss]: [0.4385, 0.24871206]\n",
            "Epoch 47 train [acc, loss]: [0.4546, 0.2426013]\n",
            "Epoch 47 val [acc, loss]: [0.4448, 0.24763818]\n",
            "Epoch 48 train [acc, loss]: [0.45834, 0.24168757]\n",
            "Epoch 48 val [acc, loss]: [0.4501, 0.24645546]\n",
            "Epoch 49 train [acc, loss]: [0.46376, 0.23993969]\n",
            "Epoch 49 val [acc, loss]: [0.4575, 0.24375606]\n",
            "Epoch 50 train [acc, loss]: [0.4715, 0.23755367]\n",
            "Epoch 50 val [acc, loss]: [0.4638, 0.24194932]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39z0nTz3piAC",
        "colab_type": "text"
      },
      "source": [
        "### Batch Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9jsK2O8pl7P",
        "colab_type": "text"
      },
      "source": [
        "Идея была высказана в 2014 году. Говорится,  что из-за смещенности градиентов нарушаются общие правила нормальности, применимые после входного слоя. Поэтому предлагается производить смещение в новый масштаб.\n",
        "\n",
        "Иными словами,\n",
        "\n",
        "$$\n",
        "    out = \\gamma \\cdot \\frac{x - \\mathrm{E}x}{\\sqrt{\\mathrm{D}x + \\varepsilon}} + \\beta,\n",
        "$$\n",
        "\n",
        "где $\\gamma$ и $\\beta$ являются обучаемыми параметрами. \n",
        "\n",
        "\n",
        "**Вопрос** Как вычислять значение $\\mathrm{E}x$, $\\mathrm{D}x$?\n",
        "\n",
        "**Ответ** Во время обучения: вычислять по batch-у, во время валидации - вычислять скользящее среднее по $\\mathrm{E}$ и $\\mathrm{D}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em06XsFT5k-8",
        "colab_type": "text"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDGIky_qwWB2",
        "colab_type": "text"
      },
      "source": [
        "### VGG\n",
        "\n",
        "Идея - использовать свертки 3 x 3 в большом количестве."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz2PyLmJwYwl",
        "colab_type": "text"
      },
      "source": [
        "### ResNet\n",
        "\n",
        "Идея - использовать residual-блоки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDsAPhbEwcvS",
        "colab_type": "text"
      },
      "source": [
        "### Inception\n",
        "\n",
        "Идея - использовать inception блоки и дополнительный loss для классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxDdOayowq-C",
        "colab_type": "text"
      },
      "source": [
        "### EffNet?\n",
        "\n",
        "ToDo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymtiQuSpw5ki",
        "colab_type": "text"
      },
      "source": [
        "### Аугментации датасетов\n",
        "\n",
        "Повороты, развороты, crop-ы, масштабирование"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NccK13pt5ms6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}